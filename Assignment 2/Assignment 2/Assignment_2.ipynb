{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52fj0bRuXgvu"
   },
   "source": [
    "# Assignment 2: SoC Module Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjjJg5d_Xgvw"
   },
   "source": [
    "## Instructions to submit the assignment\n",
    "\n",
    "- Name your jupyter notebook as `Assignment2_[StudentID].ipynb`. For instance: `Assignment2_A0123873A.ipynb`\n",
    "- Your solution notebook must contain the python code that we can run to verify the answers.\n",
    "- Upload your jupyter notebook on LumiNUS in the *Assignment 1 Submissions* folder. The folder will close at 4pm on 02/04/2021. Late submissions will receive a penalty on the grade as follows:\n",
    "  - late within 1 hour: 10% reduction in grade\n",
    "  - late within 6 hours: 30% reduction in grade\n",
    "  - late within 12 hours: 50% reduction in grade\n",
    "  - late within 1 days: 70% reduction in grade\n",
    "  - after 1 days: zero mark\n",
    "- **This is an individual assessment. Refrain from working in groups.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTnGjmPVXgvy"
   },
   "source": [
    "In this assignment we design a reccomendation engine. The recommendation engine suggests the students a module that closely matches the modules already taken by the student. The dataset comprices of two files:\n",
    "- List of modules in the School of Computing \n",
    "- List of graduated students and the modules they had taken during their studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgL9CZ-pXgvz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tjl54HB5Xgvz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "'''\n",
    "    YOU MUST USE THE RANDOM SEED WHEREVER NEEDED\n",
    "'''\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "courses = pd.read_csv(\"courses.tsv\", sep='\\t')\n",
    "students = pd.rad_csv(\"students.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKrejjTxXgv0"
   },
   "source": [
    "# Question 1: Creating the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ_EU5o9Xgv1"
   },
   "source": [
    "We want to create a sklearn pipeline to efficiently preprocess the data and prepare it for training a model. We use three different features in the `courses` data: `specialisation`, `info` and `workload`. We want to represent every feature in a numeric form and merge them to form a feature vector for every course. We do so in the following way:\n",
    "- `specialisation` represents one of the six levels of the module. For instance: CS2103 is a Software Engineering (SE) specialisation module. Encode this categorical feature into a vector. The decision of handling missing values is left to you! *(Hint: You can use `MultiLabelBinerizer` to do so.)*\n",
    "- `info` provides a short discription of the module. We want to convert it into a vector using CountVectorizer. *Don't forget to remove the stopwords* while doing so.\n",
    "-  `workload` states the intended distribution of workload over lectures, tutorials, labs and self study. We want to find the workload as the sum of individual workloads. For instnce: 3-1-1-3-2 workload transforms to 10 hours.\n",
    "\n",
    "Provide implementation for three classes that help us build the pipeline. `transformed_courses` should be a numpy array of shape `[n_courses X n_features]`.\n",
    "\n",
    "                                                                                                   (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVBlKTN6Xgv1"
   },
   "outputs": [],
   "source": [
    "class WorkloadTransformer:        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your code here\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your code here\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ_fhJkFXgv2"
   },
   "outputs": [],
   "source": [
    "class InfoTransformer:        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your answer here\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your code here\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLKGAPR1Xgv3"
   },
   "outputs": [],
   "source": [
    "class SpecTransformer:        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your code here\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        '''\n",
    "            Write your code here\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcx2rx6CXgv4"
   },
   "outputs": [],
   "source": [
    "featureTransformer = FeatureUnion([\n",
    "    ('workload_processing', Pipeline([('wrkld', WorkloadTransformer())])),\n",
    "    ('info_processing', Pipeline([('info', InfoTransformer())])),\n",
    "    ('spec_processing', Pipeline([('spec', SpecTransformer)])),\n",
    "])\n",
    "\n",
    "featureTransformer.fit(courses)\n",
    "transformeed_courses = featureTransformer.transform(courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtc4ObIlXgv5"
   },
   "source": [
    "Now we prepare our testing data in the same way we preprocessed the course. `students` data comprises of 1000 students and a list of modules they have taken. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQu6wIgYXgv6"
   },
   "source": [
    "Create `Xtest` and `Ytest` as two matrices. `Xtest`, of size `1000*5`, comprises of first five modules for every student in the list. `Ytest`, of size `1000*[remaining_modules]`, comprises of rest of the modules for every student in the list. \n",
    "We do so in order to assess the performance of the recommender. We assess the recommender based on its effectiveness to predict the modules given a list of five modules as the input.\n",
    "\n",
    "For instance: \n",
    "- `Xtest[0] = ['CS2105', 'CS4222', 'CS6270', 'CS6205', 'CS4226']`\n",
    "- `Ytest[0] = ['CS3282', 'CS6204', 'CS5223', 'CS3281', 'CS4344', 'CS5422', 'CS3237', 'CS5233']`.\n",
    "\n",
    "<div align=\"right\">(1 mark)</align>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2t2xUhYXgv6"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8-D7LhvXgv7"
   },
   "source": [
    "For every student in `Xtest`, we need to transform the list of 5 modules to the feature space using the `featureTransformer` fit on the training data. For every module we will get a feature vector of size `n_features`. We add these feature vectors to get an aggregate feature vector for very student.\n",
    "\n",
    "Write a function `getFeatureVector` that takes in the list of modules and `featureTransformer`. It returns the feature vector for the specified list of courses. For instance, `getFeatureVector(Xtest[0], featureTransformer)` will return a vector of size `n_features`.\n",
    "\n",
    "<div align=\"right\">(3 marks)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FaBqoBPXgv7"
   },
   "outputs": [],
   "source": [
    "def getFeatureVector(modules, featureTransformer):\n",
    "    '''\n",
    "        Write your code here\n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuwxpWB2Xgv7"
   },
   "source": [
    "# Question 2: Content based recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJbpI-xdXgv8"
   },
   "source": [
    "We can use a model as simple as K-nearest neighbour (KNN) to perform a content based recommendation. If we provide a list of 5 modules to the recommender, it provide us a list of modules that are similar to the specified modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQEMNzrcXgv8"
   },
   "source": [
    "`sklearn` provides `NearestNeighbors` as well as `KNeighborsClassifier`, both of which have a similar functionality. `NearestNeighbors` provides as an easy functionality to predict a list of K nearest neighbours. Therefore, we prefer it over `KNeighborsClassifier`. If we want to find K nearest points to a datapoint`d`, we need to use `n_neighbors` as K + 1 because the list includes `d` itself.\n",
    "\n",
    "You can now train the model using the training data, which comprises of `transformed_courses` and with their codes as the labels. \n",
    "<div align=\"right\">(1 mark)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezqrA0XsXgv8"
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "model = NearestNeighbors(algo = \"brute\", n_neighbors = K)\n",
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Oo47yaXgv9"
   },
   "source": [
    "It is time to see our model in action. Let's see what modules our model reommends based on the modules taken by a student.\n",
    "\n",
    "Write a function that takes in a *pre-trained* model of your choice as input and the list of modules. It returns the top-K recommendations of the model. Print the top 6 recommendations for the first student. \n",
    "<div align=\"right\">(3 marks)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH0yg5I6Xgv9"
   },
   "outputs": [],
   "source": [
    "def recommend(model, modulesTaken, k = 5):\n",
    "    '''\n",
    "        Write your code here\n",
    "    '''\n",
    "    return\n",
    "\n",
    "print(recommend(model, Xtest[0], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVVhPPoPXgv9"
   },
   "source": [
    "# Question 3: Recommender evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrxDQQWCXgv-"
   },
   "source": [
    "Is this the model any good?. To do so, we use **precision** and **recall** as our metrics. `Ytest` consists of true labels for every students. Using those labels as the ground truth, compute the precision and recall for every student. Write a code that prints values of average precision and recall for a specific value of `K` over the `students` dataset. Print the value of average precision and average recall for `K= 10`.\n",
    "\n",
    "                                                                                                     (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPyZswBBXgv-"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeR2w7IpXgv-"
   },
   "source": [
    "We observe that both precision and recall is not really great. The reason might be igh feature dimension, which may even be noisy. Append the exisiting `featureTransformer` with a PCA to reduce the dimension. \n",
    "\n",
    "Print the value of average precision and recall for `K= 10` after the introduction of PCA.\n",
    "\n",
    "                                                                                                     (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNr2Tb56Xgv_"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih2GatUQXgv_"
   },
   "source": [
    "Extend the code to perform a grid search for the value of `K` that provides the best `F1_score`. Try for values of K from 1 to 10.\n",
    "\n",
    "                                                                                                     (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzTUXzCnXgv_"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0R5ehXhXgv_"
   },
   "source": [
    "# Bonus question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2y3bYohXgv_"
   },
   "source": [
    "Can you provide some **concrete** (something that you can implement) suggestions to improve the performance of the system?\n",
    "\n",
    "                                                                                                    (2 marks)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
