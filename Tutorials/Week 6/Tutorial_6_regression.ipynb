{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF5mcXIWy7wL"
      },
      "source": [
        "# Week 6 - Linear Regression\n",
        "\n",
        "## Learning Objectives\n",
        "+ Introduction to Statsmodel\n",
        "+ Implementing simple linear regression\n",
        "+ Estimating coefficients and analyzing the model\n",
        "+ Multiple Linear Regression and its difference with SLR\n",
        "\n",
        "For this tutorial, you would need statsmodel installed on your system.\n",
        "\n",
        "The tutorial is using the case study covered in the  textbook \"An introduction to statistical learning: with applications in R\" by James G. et al. ([link](https://link-springer-com.libproxy1.nus.edu.sg/book/10.1007/978-1-4614-7138-7)). The codes are written using this [notebook](https://github.com/justmarkham/DAT4/blob/master/notebooks/08_linear_regression.ipynb) and this [notebook](https://nbviewer.jupyter.org/github/JWarmenhoven/ISL-python/blob/master/Notebooks/Chapter%203.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qukyJI3qy7wP"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "The Advertising data set consists of the sales of that product in 200 different markets, along with advertising budgets for the product in each of those markets for three different media: TV, radio, and newspaper. Say, you are a data analyst hired to provide advice on how to improve sales of a particular product.\n",
        "\n",
        "It is not possible for your client to directly increase sales of the product. On the other hand, they can control the advertising expenditure in each of the three media. Therefore, if you determine that there is an association between advertising and sales, then you can instruct your client to adjust advertising budgets, thereby indirectly increasing sales.\n",
        "In other words, your goal is to develop an **accurate model that can be used to predict sales on the basis of the three media budgets**.\n",
        "\n",
        "The sales is in thousands of units and advertisement budges are in thousands of dollars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9KmErcOy7wQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "metadata": {
        "id": "AhJNZVX8D5-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "-Ehb3aJdy7wS"
      },
      "outputs": [],
      "source": [
        "advertising = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IT5006/Week 6/Advertising.csv', index_col=0)\n",
        "advertising.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Hepqu08Wy7wU"
      },
      "outputs": [],
      "source": [
        "advertising.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qyjFBSHy7wU"
      },
      "source": [
        "# Introduction to Statsmodels\n",
        "\n",
        "As the name implies, statsmodels is a Python library built specifically for statistics. Statsmodels is built on top of NumPy, SciPy, and matplotlib, but it contains more advanced functions for statistical testing and modeling that you won’t find in numerical libraries like NumPy or SciPy. To know more about this package follow the tutorials in this [link](https://www.statsmodels.org/stable/user-guide.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOKitXn-y7wV"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twg3YIM_y7wW"
      },
      "source": [
        "```Statsmodels``` allows users to fit statistical models using R-style formulas too. The ```formula.api``` hosts many of the same functions found in ```api``` (e.g. OLS, GLM), but it also holds lower case counterparts for most of these models. In general, lower case models accept ```formula``` and ```df``` arguments, whereas upper case ones take ```endog``` and ```exog``` design matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKnr1tD7y7wX"
      },
      "source": [
        "# Simple Linear Regression\n",
        "\n",
        "It predicts a response *Y* on the basis of a single predictor variable *X*. It assumes an approximately linear relationship between *X* and *Y*. \n",
        "\n",
        "We can regress sales onto TV by fitting the model:\n",
        "$sales \\approx \\beta_{0} + \\beta_{1} \\times TV$\n",
        "\n",
        "Before making predictions, we must data to estimate the coefficients. Let us plot the least squares fit for the regression of sales onto TV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "8dtlqPl2y7wX"
      },
      "outputs": [],
      "source": [
        "sns.regplot(advertising.TV, advertising.Sales, order=1)\n",
        "plt.ylim(ymin=0);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We demonstrate two ways to perform the regression:"
      ],
      "metadata": {
        "id": "5dIOf0ZBCBgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0medLwey7wY"
      },
      "outputs": [],
      "source": [
        "X = advertising[['TV']]\n",
        "y = advertising[['Sales']]\n",
        "\n",
        "est = sm.OLS(y, X).fit() \n",
        "est.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "WruqItm_y7wZ"
      },
      "outputs": [],
      "source": [
        "est = smf.ols('Sales ~ TV', advertising).fit()\n",
        "est.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv1iIcQ6y7wZ"
      },
      "source": [
        "## Residuals and assessing accuracy of model\n",
        "\n",
        "### Residual and RSS\n",
        "\n",
        "**Residual** ($e_{i} = y_{i}-\\hat{y_{i}}$) is the difference between the $i^{th}$ observed response value and the $i^{th}$ response value that is predicted by our linear model. The least squares approach chooses the $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ to minimize the **Residual sum of squares** ($ e^{2}_{1} + e^{2}_{2} + ...$).\n",
        "\n",
        "From the results obtained above, we can see the coefficient estimates as follows:\n",
        "+ $\\hat{\\beta_{0}} = 7.03$\n",
        "+ $\\hat{\\beta_{1}} = 0.0475$\n",
        "\n",
        "In other words, an additional 1000 dollars spent on TV advertising is associated with selling approximately 47.5 additional units of the product. This is because the $\\beta_{1}$ is the slope - the average increase in sales associated with a one-unit\n",
        "increase in TV budget (which is in thousands of dollars)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "est.params"
      ],
      "metadata": {
        "id": "aPjPLdoiUhIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-jlKwx_Yy7wa"
      },
      "outputs": [],
      "source": [
        "(est.params[0] + est.params[1]*advertising.TV)\n",
        "# RSS with regression coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz5ev_dty7wa"
      },
      "outputs": [],
      "source": [
        "est.ssr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp_wyvQKy7wa"
      },
      "source": [
        "Besides the summary presented above, the [```OLSResults```](https://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.OLSResults.html) class in ```statsmodels``` has various attributes which can be accessed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ylVxJNny7wb"
      },
      "source": [
        "\n",
        "### Residual Standard Error\n",
        "\n",
        "Here we note that we have access to a set of observations from which we can compute the least squares line; however, the population regression line is unobserved - which would be the \"true\" model. To conduct hypothesis testing and to find the confidence intervals of our coefficients, we need to find the residual standard error. \n",
        "\n",
        "The residual sum of squares can be used to compute the residual standard error which is given by the formula:\n",
        "$RSE = \\sqrt{\\frac{RSS}{n-2}}$ ([link](https://https://hastie.su.domains/ISLR2/ISLRv2_website.pdf))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Residual standard error:\", np.sqrt(est.ssr/(len(advertising.TV)-2)))"
      ],
      "metadata": {
        "id": "3w_Le_JPldO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0FKBSyJy7wc"
      },
      "source": [
        "The RSE is found to be 3.26. In other words, actual sales in each market deviate from the true regression line by approximately 3.26 units, on average."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The residual standard error can be used to calculate the standard error of coefficients in the regression. These can then be used to compute hypothesis tests such as whether there is a relationship between X and Y (implying $H0: \\beta_{1} = 0$). We need to do the following:\n",
        "+ Calculate the standard error for each coefficient\n",
        "+ Calculate the t test value for a 95% confidence interval\n",
        "+ Calculate the confidence interval for each coefficient\n",
        "\n",
        "The confidence interval is: $\\frac{RSE}{\\sqrt{\\sum{(y_i - \\overline{y_i})^2}}}$"
      ],
      "metadata": {
        "id": "oIZwSlQPtqtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(est.ssr/(len(advertising.TV)-2)) / np.sqrt(np.sum((advertising.TV - np.mean(advertising.TV))**2))"
      ],
      "metadata": {
        "id": "BVQ3bYFGx4qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "est.bse"
      ],
      "metadata": {
        "id": "-s6N9VzqxpDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import t\n",
        "tvalue = t.ppf(1-0.025, df = 198)\n",
        "tvalue"
      ],
      "metadata": {
        "id": "H_olsnuh_Ysa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confidence interval for intercept\", est.params[0] - est.bse[0] * tvalue, \"to\", est.params[0] + est.bse[0] * tvalue)\n",
        "print(\"Confidence interval for TV coefficient\", est.params[1] - est.bse[1] * tvalue, \"to\", est.params[1] + est.bse[1] * tvalue)"
      ],
      "metadata": {
        "id": "_1R90aCC6C0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "est.conf_int(alpha = .05)"
      ],
      "metadata": {
        "id": "rPfLfOyMuw4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, in the computed OLS output, we observe that $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ are very large relative to their\n",
        "standard errors, so the t-statistics are also large; the probabilities of seeing such values if H0 is true are virtually zero. \n",
        "\n",
        "We can reject the null hypothesis that $\\beta_{0} = 0$, which leads us to conclude that in the absense of TV expenditure, the sales are non-zero. \n",
        "\n",
        "\n",
        "We can also reject the null hypothesis that $\\beta_{1} = 0$, which leads us to conclude that for each $1,000 increase in television advertising, there will be an average increase in sales of between 42 and 53 units. \n",
        "\n",
        "$\\beta_{0}$ and $\\beta_{1}$ are *statistically significant*.\n"
      ],
      "metadata": {
        "id": "kQFUKUU2ld4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "est.tvalues"
      ],
      "metadata": {
        "id": "0MFuDH6H0jbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R-squared statistic\n",
        "The $R^{2}$ statistic provides an alternative measure of fit. It takes the form of a proportion—the proportion of variance\n",
        "explained—and so it always takes on a value between 0 and 1, and is independent of the scale of Y.\n",
        "\n",
        "$ R^{2} = 1 - \\frac{RSS}{TSS}$\n",
        "\n",
        "TSS measures the total variance in the response Y , and can be squares thought of as the amount of variability inherent in the response before the regression is performed. In contrast, RSS measures the amount of variability that is left unexplained after performing the regression. An $R^{2}$ statistic that is close to 1 indicates that a large proportion of the variability in the response has been explained by the regression."
      ],
      "metadata": {
        "id": "YImtjFdBhc3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nwWvIPzly7wb"
      },
      "outputs": [],
      "source": [
        "print('R-squred: ', est.rsquared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz7OZU6y7wc"
      },
      "source": [
        "Now let us plot the residuals with respect to the predicted values.  \n",
        "\n",
        "For this plot, we can use [```sns.residplot```](https://seaborn.pydata.org/generated/seaborn.residplot.html) which will regress y on x and then draw a scatterplot of the residuals. So the graph we will obtain will be a scatterplot for the residuals with the predictor variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yscfpAQIy7wc"
      },
      "outputs": [],
      "source": [
        "sns.residplot(advertising[\"TV\"], advertising['Sales'], lowess=True, order=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voLx0EiTy7wd"
      },
      "source": [
        " Ideally, this should look like a random scatter plot with zero mean and constant variance for all predicted values. Our residual plot doesn't look like an ideal residual plot. This is because the mean line of the residuals is not close to zero for all values of  $\\hat{y}$ and the variance seems to be increasing with the predictor, TV. This means that our model assumptions are being violated.\n",
        " \n",
        "Among many possible reasons for this violation, the following are usual suspects:\n",
        "+ There is another feature other than TV that affects sales.\n",
        "+ The relation between TV and sales is not linear. \n",
        "\n",
        "We will implement the first fix using Multiple Linear Regression. But first let's break the model linearity assumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT-bRKBfy7wd"
      },
      "source": [
        "# Polynomial Regression and Heteroscedasticity\n",
        "\n",
        "As we see, the assumption of linearity between TV and sales might not hold. However, from the residual plot, we observe more more clearly that the standard deviation of residual keeps on increasing as the magnitude of predicted response increases. This issue is called **heteroscedasticity**. To address this issue, we could transform our response variable y with functions such as $\\sqrt y$, $\\log(y)$. We use the concept of indicator function denoted by $I(.)$ that returns a 1 if the condition is true, otherwise returns a 0. It represents a new variable, $TV^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "t7ctPacMy7wd"
      },
      "outputs": [],
      "source": [
        "poly_est = smf.ols('np.log(Sales) ~ TV + I(TV**2)', data=advertising).fit()\n",
        "poly_est.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the values in the model:"
      ],
      "metadata": {
        "id": "5J9Brn2DLP2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smf.ols('np.log(Sales) ~ TV + I(TV**2)', data=advertising).exog[:5,]"
      ],
      "metadata": {
        "id": "gJ4_da05LN6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "h_GiK3d0y7wd"
      },
      "outputs": [],
      "source": [
        "sns.residplot(advertising[\"TV\"], np.log(advertising['Sales']), lowess=True, order=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPNECQ_hy7we"
      },
      "source": [
        "# Performing model prediction\n",
        "\n",
        "Let us say, the client invests 50,000 in TV budget. What would we expect our sales to be? We can use the multiple linear regression model we have estimated to do the prediction for us. \n",
        "\n",
        "NOTE: The sklearn library also has implementation of linear regression which can be used for such prediction. The API is the same one you are already familiar with - the ```fit```, ```transform``` and ```fit_transform``` methods for the ```sklearn.linear_model.LinearRegression```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNJCWjgey7we"
      },
      "outputs": [],
      "source": [
        "X_test = pd.DataFrame({'TV': [50]})\n",
        "est.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO0TcZgyy7wf"
      },
      "source": [
        "Linear models rely upon a lot of assumptions (such as the features being independent), and if those assumptions are violated (which they usually are), R-squared and p-values are less reliable. R-squared will always increase as you add more features to the model, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model. There is alternative to R-squared called adjusted R-squared that penalizes model complexity (to control for overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, to select the best model to use for prediction, you might want to resort to the classical cross validation. This is again easily possible using the ```sklearn``` API."
      ],
      "metadata": {
        "id": "B3vX-XvrPWT6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfhMr7ZAy7wf"
      },
      "source": [
        "```statsmodels``` provides a function [```wls_prediction_std```](https://www.kite.com/python/docs/statsmodels.graphics.regressionplots.wls_prediction_std) that takes the result object of regression and provides the lower and upper values within which the prediction will lie with 95% confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7IMWOnGy7wf"
      },
      "outputs": [],
      "source": [
        "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
        "\n",
        "def get_vis_dataframe(est, X, y, ylabel='yobs', yhlabel='ypred'):\n",
        "    std, upper,lower = wls_prediction_std(est)\n",
        "    rvis = X.copy()\n",
        "    rvis[ylabel], rvis[yhlabel]= y, est.predict(X)\n",
        "    rvis['resid'], rvis['upper'], rvis['lower'] = est.resid, upper, lower\n",
        "    rvis2 = pd.melt(rvis[['TV', 'ypred', 'upper', 'lower']], id_vars = 'TV', var_name='Estimate') # massage the df into the format we want\n",
        "    return rvis, rvis2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ww_Yubu-y7wf"
      },
      "outputs": [],
      "source": [
        "linvis, linvis2 = get_vis_dataframe(est, X, y)\n",
        "linvis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqDmD5sUy7wg"
      },
      "outputs": [],
      "source": [
        "linvis2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Nhs0IZAay7wg"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "sns.scatterplot(data=linvis, x='TV', y='yobs', ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-KKk-7uy7wg"
      },
      "source": [
        "# Multiple Linear Regression\n",
        "\n",
        "When we have more than one predictor variables, we use multiple linear regression. It essentially gives each predictor a separate slope coefficient in a single model. So, if we want to analyze if the radio and newspapers are also associated with sales, we can do a multiple linear regression as:\n",
        "\n",
        "$sales \\approx \\beta_{0} + \\beta_{1} \\times TV + \\beta_{2} \\times radio + \\beta_{3} \\times newspaper$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvuMt4Szy7wh"
      },
      "source": [
        "Let us first do simple linear regression on these features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uidffm_Dy7wh"
      },
      "outputs": [],
      "source": [
        "est = smf.ols('Sales ~ Radio', advertising).fit()\n",
        "est.summary().tables[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "0ml9Wdlhy7wh"
      },
      "outputs": [],
      "source": [
        "est = smf.ols('Sales ~ Newspaper', advertising).fit()\n",
        "est.summary().tables[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKntAXsRy7wh"
      },
      "source": [
        "From the simple linear regression, we can say that a 1000 dollars increase in spending on radio advertising is associated with an average increase in sales by around 203 units, while the same increase in spending on newspaper advertising is associated with an average increase in sales by around 55 units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "mlJeZZWny7wh"
      },
      "outputs": [],
      "source": [
        "mul_est = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=advertising).fit()\n",
        "\n",
        "# print the coefficients\n",
        "mul_est.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "iNLufRDCy7wi"
      },
      "outputs": [],
      "source": [
        "print(mul_est.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn3qaKPBy7wi"
      },
      "source": [
        "We notice that the multiple regression coefficient estimates for TV and Radio are pretty similar to the simple linear regression coefficients. However, while the newspaper regression coefficient estimate in SLR was significantly non-zero, the coefficient estimate for newspaper in the multiple regression model is close to zero, and the corresponding p-value is no longer significant, with a value around 0.86.\n",
        "\n",
        "This difference stems from the fact that in the simple regression case, the slope term represents the average effect of a 1000 dollars increase in newspaper advertising, ignoring other predictors such as TV and radio. In contrast, in the multiple regression setting, the coefficient for newspaper represents the average effect of increasing newspaper spending by 1000 dollars while holding TV and radio fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hW37idAy7wi"
      },
      "outputs": [],
      "source": [
        "advertising.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcfcXyWVy7wi"
      },
      "source": [
        "From the correlation matrix, we notice that the correlation between radio and newspaper is 0.35. This reveals a tendency to spend more on newspaper advertising in markets where more is spent on radio advertising. \n",
        "\n",
        "Now suppose that the multiple regression is correct and newspaper advertising has no direct impact on sales, but radio advertising does increase sales. Then in markets where we spend more on radio our sales will tend to be higher, and as our correlation matrix shows, we also tend to spend more on newspaper advertising in those same markets. Hence, in a simple linear regression which only examines sales versus newspaper, we will observe that higher values of newspaper tend to be associated with higher values of sales, *even though newspaper advertising does not actually affect sales*. So newspaper sales are a surrogate for radio advertising; newspaper gets “credit” for the effect of radio on sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP2vgEZNy7wi"
      },
      "source": [
        "## F-statistic\n",
        "\n",
        "The F value is the ratio of the mean regression sum of squares divided by the mean error sum of squares. Its value will range from zero to an arbitrarily large number. In multiple linear regression, the null hypothesis we look at is if there is a relationship between the response and predictor.\n",
        "\n",
        "+ H0: $\\beta_{1} = \\beta_{2} = \\beta_{3} = ... = 0$\n",
        "\n",
        "We can assess the accuracy of the multiple regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic1aLWBey7wj"
      },
      "outputs": [],
      "source": [
        "print(\"RSE:\", mul_est.resid.std())\n",
        "print(\"R squared:\", mul_est.rsquared)\n",
        "print(\"F-statistic:\", mul_est.fvalue)\n",
        "print(\"F-test pvalue:\", mul_est.f_pvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PmCu1Iy7wj"
      },
      "source": [
        "The large F-statistic suggests that *at least one of the advertising media must be related to sales* (at least one is non-zero). We see that the probability of the f-statistic is close to zero, so we have extremely strong evidence that at least one of the media is associated with increased sales.\n",
        "\n",
        "Suppose our null hypothesis is that specific coefficients are zero. The t-statistic for each predictor provide information about whether each individual predictor is related to the response, after adjusting for the other\n",
        "predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZAyAkGLy7wj"
      },
      "source": [
        "## Residual Plots for the multiple linear regression\n",
        "\n",
        "Let us again plot the residual plots to visualize the trend in residuals as we did for simple linear regression. As the residplot function is not designed for the multiple linear regression, but only for simple linear regression, we will use the get_vis_dataframe function to get predictions from the model to plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "VjqikHlqy7wj"
      },
      "outputs": [],
      "source": [
        "X = advertising[[\"TV\", \"Radio\", \"Newspaper\"]]\n",
        "y = advertising[[\"Sales\"]]\n",
        "\n",
        "mulvis, mulvis2 = get_vis_dataframe(mul_est, X, y)\n",
        "\n",
        "sns.residplot(mulvis[\"ypred\"], mulvis.resid, lowess=True, order=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJk_yaaty7wj"
      },
      "outputs": [],
      "source": [
        "predictors = [\"TV\", \"Radio\", \"Newspaper\"]\n",
        "poly2_predictors = []\n",
        "for p in predictors:\n",
        "    poly2_predictors.append('{} + I({}**2)'.format(p, p))\n",
        "print(poly2_predictors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4V4IO07ky7wk"
      },
      "outputs": [],
      "source": [
        "poly_mul_est = smf.ols(formula='Sales ~'+ ' + '.join(poly2_predictors), data=advertising).fit()\n",
        "print(poly_mul_est.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot the residual plot of the multiple polynomial regression."
      ],
      "metadata": {
        "id": "fn5FIUBj4D-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9lVzVEfgy7wk"
      },
      "outputs": [],
      "source": [
        "mulvis, mulvis2 = get_vis_dataframe(poly_mul_est, X, y)\n",
        "\n",
        "sns.residplot(mulvis[\"ypred\"], mulvis[\"yobs\"], lowess=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot is equivalent to:"
      ],
      "metadata": {
        "id": "zwYsS0D329bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(mulvis.ypred, mulvis.resid )"
      ],
      "metadata": {
        "id": "D5zaTaMUdRSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also plot the residual plot of the multiple linear regression. Will the residual plot with ```order = 2``` be the same as that of the polynomial regression above?"
      ],
      "metadata": {
        "id": "7Raa2P2K4W_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZltYaAt4y7wk"
      },
      "outputs": [],
      "source": [
        "mulvis, mulvis2 = get_vis_dataframe(mul_est, X, y)\n",
        "sns.residplot(mulvis[\"ypred\"], mulvis[\"yobs\"], lowess=True, order=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why the line is straight when using order=2 in resid plot, while our regression model does not yield the same plot despite taking second degree terms?"
      ],
      "metadata": {
        "id": "BeH8SPTq3CTz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Tutorial 6 regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}